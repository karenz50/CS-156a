{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1 and 2\n",
        "\n",
        "1: B\n",
        "\n",
        "2: D"
      ],
      "metadata": {
        "id": "7fJtOOeQLurk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A56kiTxSGXuz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trials = 1000\n",
        "num_flips = 10\n",
        "num_runs = 100000\n",
        "\n",
        "epsilon = .3\n",
        "e_out = .5\n",
        "hoeffding_bound = 2 * np.exp(-2 * epsilon ** 2 * num_flips)\n",
        "\n",
        "def coin_run():\n",
        "  coin_flips = np.random.randint(2, size=(num_trials, num_flips))\n",
        "\n",
        "  v_1 = coin_flips[0].sum() / num_flips\n",
        "\n",
        "  c_rand = coin_flips[np.random.randint(num_trials)]\n",
        "  v_rand = c_rand.sum() / num_flips\n",
        "\n",
        "  heads_min = np.count_nonzero(coin_flips, axis=1)\n",
        "  c_min = coin_flips[np.argmin(heads_min)]\n",
        "  v_min = c_min.sum() / num_flips\n",
        "\n",
        "  return v_1, v_rand, v_min\n",
        "\n",
        "all_v = np.array([coin_run() for i in range(num_runs)])"
      ],
      "metadata": {
        "id": "FhouVaCCMBbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1\n",
        "print(np.mean(all_v, axis=0)[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMhAH64VOmQu",
        "outputId": "333a90a0-7939-4a10-d5eb-b09d8934076b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.037595999999976766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2\n",
        "def check_difference(x):\n",
        "    return math.fabs(x - e_out) > epsilon\n",
        "\n",
        "func = np.vectorize(check_difference)\n",
        "print(np.mean(func(all_v), axis=0) <= hoeffding_bound)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2PKsDrjPZLc",
        "outputId": "229ae8a1-177f-4581-930b-709c2417524d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True  True False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5-10"
      ],
      "metadata": {
        "id": "EGGgRM9lPtMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_point():\n",
        "  return [np.random.uniform(-1, 1), np.random.uniform(-1, 1)]\n",
        "\n",
        "# get corresponding y_n by evaluating target function on each x_n\n",
        "def find_y(x, m, b):\n",
        "  pos = m * x[0] - x[1] + b\n",
        "  return np.sign(pos)\n",
        "\n",
        "def generate_points(N):\n",
        "  pt1 = random_point()\n",
        "  pt2 = random_point()\n",
        "\n",
        "  m = (pt2[1] - pt1[1]) / (pt2[0] - pt1[0]) # find slope of line\n",
        "  b = pt1[1] - m * pt1[0]                   # find y-intercept of line\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "  for i in range(N):\n",
        "    new_pt = random_point()\n",
        "    y = find_y(new_pt, m, b)\n",
        "    X.append(new_pt)\n",
        "    Y.append(y)\n",
        "\n",
        "  return np.array(X), np.array(Y)"
      ],
      "metadata": {
        "id": "NnLSWgeMPrRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_ITER = 10000\n",
        "\n",
        "def pla(X, Y, N, w):\n",
        "  iterations = 0\n",
        "  ones = np.ones((N, 1))\n",
        "  temp_X = np.hstack((ones, X[:N]))\n",
        "\n",
        "  while iterations < MAX_ITER:\n",
        "    misclassified_pts = []\n",
        "\n",
        "    for i in range(N):\n",
        "      if np.sign(np.dot(w.T, temp_X[i])) != Y[i]:\n",
        "        misclassified_pts.append(i)\n",
        "\n",
        "    if not misclassified_pts:\n",
        "      break\n",
        "\n",
        "    random_idx = np.random.choice(misclassified_pts)\n",
        "    w += Y[random_idx] * temp_X[random_idx]\n",
        "\n",
        "    iterations += 1\n",
        "\n",
        "  return iterations"
      ],
      "metadata": {
        "id": "47k2O6oSFV1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression:\n",
        "  def __init__(self, X, Y, N):\n",
        "    self.weights = np.zeros(X.shape[1])\n",
        "\n",
        "    ones = np.ones((X.shape[0], 1))\n",
        "    self.X = np.hstack((ones, X))\n",
        "    self.Y = Y\n",
        "    self.N = N\n",
        "\n",
        "  def fit(self):\n",
        "    temp_X = self.X[:self.N]\n",
        "\n",
        "    X_transpose = np.transpose(temp_X)\n",
        "    X_transpose_X = np.matmul(X_transpose, temp_X)\n",
        "    X_inverse = np.linalg.inv(X_transpose_X)\n",
        "    X_dagger = np.matmul(X_inverse, X_transpose)\n",
        "\n",
        "    self.weights = np.matmul(X_dagger, self.Y[:self.N])\n",
        "\n",
        "  def predict(self, X):\n",
        "    return np.sign(np.matmul(X, self.weights))\n",
        "\n",
        "  def calculate_error(self, f, g):\n",
        "    return np.mean(f != g)\n",
        "\n",
        "  def calculate_e_in(self):\n",
        "    return self.calculate_error(self.predict(self.X[:N]), self.Y[:N])\n",
        "\n",
        "  def calculate_e_out(self):\n",
        "    return self.calculate_error(self.predict(self.X[N:]), self.Y[N:])"
      ],
      "metadata": {
        "id": "FAhC8hR00yUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5: C\n",
        "\n",
        "6: C\n",
        "\n",
        "7: A\n",
        "\n",
        "8: D\n",
        "\n",
        "9: A\n",
        "\n",
        "10: B"
      ],
      "metadata": {
        "id": "L-fMZN_bE1iP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 5 and 6\n",
        "N = 100\n",
        "runs = 1000\n",
        "\n",
        "e_in = 0\n",
        "e_out = 0\n",
        "\n",
        "for i in range(runs):\n",
        "  X, Y = generate_points(N + 1000)\n",
        "  lin_reg = LinearRegression(X, Y, N)\n",
        "  lin_reg.fit()\n",
        "  e_in += lin_reg.calculate_e_in()\n",
        "  e_out += lin_reg.calculate_e_out()\n",
        "\n",
        "print(e_in / runs)\n",
        "print(e_out / runs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htJk3vrVJVyG",
        "outputId": "292c03fb-689a-473e-aa45-9e4fbcd00bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.041200000000000125\n",
            "0.04917799999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 7\n",
        "N = 10\n",
        "avg_iter = 0\n",
        "\n",
        "for i in range(runs):\n",
        "  X, Y = generate_points(N)\n",
        "  lin_reg = LinearRegression(X, Y, N)\n",
        "  lin_reg.fit()\n",
        "\n",
        "  cur_iter = pla(X, Y, N, lin_reg.weights)\n",
        "  avg_iter += cur_iter\n",
        "\n",
        "print(avg_iter / runs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aCvmnRFExTS",
        "outputId": "950a901f-9dbb-46da-9950-cf944ceb318a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flip_for_noise(Y):\n",
        "  n = len(Y)\n",
        "  num_flips = int(0.1 * n)\n",
        "  indices_to_flip = np.random.choice(n, num_flips, replace=False)\n",
        "  Y[indices_to_flip] = -Y[indices_to_flip]\n",
        "\n",
        "  return Y\n",
        "\n",
        "def target_func(x_1, x_2):\n",
        "  return np.sign(x_1 ** 2 + x_2 ** 2 - .6)\n",
        "\n",
        "def generate_noisy_points(N):\n",
        "  pt1 = random_point()\n",
        "  pt2 = random_point()\n",
        "\n",
        "  m = (pt2[1] - pt1[1]) / (pt2[0] - pt1[0]) # find slope of line\n",
        "  b = pt1[1] - m * pt1[0]                   # find y-intercept of line\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "  for i in range(N):\n",
        "    new_pt = random_point()\n",
        "    y = target_func(new_pt[0], new_pt[1])\n",
        "    X.append(new_pt)\n",
        "    Y.append(y)\n",
        "\n",
        "  return np.array(X), flip_for_noise(np.array(Y))"
      ],
      "metadata": {
        "id": "TD0GuV9aG_Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 8\n",
        "N = 1000\n",
        "e_in = 0\n",
        "\n",
        "for i in range(runs):\n",
        "  X, Y = generate_noisy_points(N)\n",
        "  lin_reg = LinearRegression(X, Y, N)\n",
        "  lin_reg.fit()\n",
        "  e_in += lin_reg.calculate_e_in()\n",
        "\n",
        "print(e_in / runs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qICGNzfaHsPc",
        "outputId": "165bc5f8-a029-41dc-959d-041a4d80f699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5036210000000005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_features(X):\n",
        "    x1 = X[:, 0]\n",
        "    x2 = X[:, 1]\n",
        "\n",
        "    x1x2 = x1 * x2\n",
        "    x1_squared = x1 ** 2\n",
        "    x2_squared = x2 ** 2\n",
        "\n",
        "    transform_X = np.column_stack((x1, x2, x1x2, x1_squared, x2_squared))\n",
        "\n",
        "    return transform_X"
      ],
      "metadata": {
        "id": "hfv63CVyLkpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 9 and 10\n",
        "avg_weights = np.zeros(6)\n",
        "e_out = 0\n",
        "\n",
        "for i in range(runs):\n",
        "  X, Y = generate_noisy_points(N + 1000)\n",
        "  X = transform_features(X)\n",
        "  lin_reg = LinearRegression(X, Y, N)\n",
        "  lin_reg.fit()\n",
        "  avg_weights += lin_reg.weights\n",
        "  e_out += lin_reg.calculate_e_out()\n",
        "\n",
        "print(avg_weights / runs)\n",
        "print(e_out / runs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOaoJbNzJqm3",
        "outputId": "128f7132-1d83-41be-fb39-f7fb33516114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-9.92119992e-01 -8.82924079e-04  6.85998494e-04 -8.51484226e-03\n",
            "  1.55706379e+00  1.55667364e+00]\n",
            "0.1262000000000001\n"
          ]
        }
      ]
    }
  ]
}